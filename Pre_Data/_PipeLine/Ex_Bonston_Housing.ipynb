{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Bonston Housing](https://github.com/phamdinhkhanh/datasets/blob/master/BostonHousing.csv) about predict Bonston home price.\n",
    "\n",
    "1. Describe statistics & plot for continuous and category variables. Evaluating for distribution properties of each var.\n",
    "\n",
    "2. Completed 1 pipeline to processing raw data to useful data.\n",
    "\n",
    "3. Spilit train & test set and choose metric for problem.\n",
    "\n",
    "4. Choose model, cross-validation to training and evaluating in training set.\n",
    "\n",
    "5. Re do ex 4 with other models \n",
    "\n",
    "6. Plot result of model to choose best model.\n",
    "\n",
    "7. Based on best model, Grid Search in parameter space of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston Housing Dataset is a derived from information collected by the U.S. Census Service concerning housing in the area of [ Boston MA](http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html). The following describes the dataset columns:\n",
    "\n",
    "* CRIM - per capita crime rate by town\n",
    "* ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* INDUS - proportion of non-retail business acres per town.\n",
    "* CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "* NOX - nitric oxides concentration (parts per 10 million)\n",
    "* RM - average number of rooms per dwelling\n",
    "* AGE - proportion of owner-occupied units built prior to 1940\n",
    "* DIS - weighted distances to five Boston employment centres\n",
    "* RAD - index of accessibility to radial highways\n",
    "* TAX - full-value property-tax rate per \\$10,000\n",
    "* PTRATIO - pupil-teacher ratio by town\n",
    "* B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "* LSTAT - % lower status of the population\n",
    "* MEDV - Median value of owner-occupied homes in \\$1000's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/phamdinhkhanh/datasets/master/BostonHousing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From get-go, two data coulmns show interesting summeries. They are : ZN (proportion of residential land zoned for lots over 25,000 sq.ft.) with 0 for 25th, 50th percentiles. \n",
    "* Second, CHAS: Charles River dummy variable (1 if tract bounds river; 0 otherwise) with 0 for 25th, 50th and 75th percentiles. These summeries are understandable as both variables are conditional + categorical variables. \n",
    "* First assumption would be that these coulms may not be useful in regression task such as predicting MEDV (Median value of owner-occupied homes).\n",
    "* Another interesing fact on the dataset is the max value of MEDV. From the original data description, it says: Variable #14 seems to be censored at 50.00 (corresponding to a median price of $50,000). Based on that, values above 50.00 may not help to predict MEDV. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Visualize continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot to check outliers\n",
    "fig, axs = plt.subplots(nrows=2, ncols=7, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in df.items():\n",
    "    sns.boxplot(y=k, data=df, ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns like CRIM, ZN, RM, B seems to have outliers -> see the outliers percentage in every column.\n",
    "for k, v in df.items():\n",
    "    q1 = v.quantile(0.25)\n",
    "    q3 = v.quantile(0.75)\n",
    "    irq = q3 - q1\n",
    "    v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n",
    "    perc = np.shape(v_col)[0] * 100.0 / np.shape(df)[0]\n",
    "    print(\"Column %s outliers = %.2f%%\" % (k, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove MEDV outliers (MEDV = 50.0) before plotting more distributions\n",
    "df = df[~(df['medv'] >= 50.0)]\n",
    "print(np.shape(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destiny\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 7, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in df.items():\n",
    "    sns.distplot(v, ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram also shows that columns CRIM, ZN, B has highly skewed distributions. Also MEDV looks to have a normal distribution (the predictions) and other colums seem to have norma or bimodel ditribution of data except CHAS (which is a discrete variable).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pairwise correlation on data ≈ Heatmapb\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(df.corr().abs(),  annot=True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From correlation matrix, we see TAX and RAD are highly correlated features. The columns LSTAT, INDUS, RM, TAX, NOX, PTRAIO has a correlation score above 0.5 with MEDV which is a good indication of using as predictors. Let's plot these columns against MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter (preprocessing remove outliers)\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Remove outliers x \n",
    "column_sels = ['lstat', 'indus', 'nox', 'ptratio', 'rm', 'tax', 'dis', 'age']\n",
    "x = df.loc[:,column_sels]\n",
    "y = df['medv']\n",
    "x = pd.DataFrame(min_max_scaler.fit_transform(x), columns=column_sels)\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(ncols=4, nrows=2, figsize=(20, 10))\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for i, k in enumerate(column_sels):\n",
    "    sns.regplot(y=y, x=x[k], ax=axs[i])\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with these analsis, we may try predict MEDV with 'LSTAT', 'INDUS', 'NOX', 'PTRATIO', 'RM', 'TAX', 'DIS', 'AGE' features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Spilit Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state= 42)\n",
    "\n",
    "X_train = df_train.copy()\n",
    "y_train = df_train.pop(\"medv\")  # Return item and drop from frame.\n",
    "X_test = df_test.copy()\n",
    "y_test = df_test.pop(\"medv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "num_pl = Pipeline(\n",
    "    steps= [(\"imputer\", KNNImputer(n_neighbors = 7)),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(('num', num_pl, num_cols))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Merge pipeline processor with model to full pipeline\n",
    "completed_pl = Pipeline(\n",
    "    steps = [(\"preprocessor\", preprocessor),\n",
    "    (\"ridge\", Ridge())]\n",
    ")\n",
    "\n",
    "# Training \n",
    "completed_pl.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy \n",
    "print(completed_pl.score(X_train, y_train), completed_pl.score(X_test, y_test), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross-Validation\n",
    "Predict Problem: Accuracy ≈ MSE > KFold > Check Pipeline for more algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Formula to calcute score\n",
    "metric = make_scorer(mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# K Fold\n",
    "cv = KFold(n_splits= 40)\n",
    "\n",
    "# Accuracy\n",
    "scores = cross_val_score(completed_pl, X_train, y_train, scoring = metric, cv = cv, n_jobs = -1)\n",
    "scores.mean()   # Must calcute mean score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# List model chose\n",
    "models = [Ridge(), SVR(), DecisionTreeRegressor(), KNeighborsRegressor(), GradientBoostingRegressor()]\n",
    "\n",
    "# Identifying KFold\n",
    "cv = KFold(n_splits=40)\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "# Accracy\n",
    "for model in models:\n",
    "  completed_pl = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "    ('classifier', model)])\n",
    "\n",
    "  scores = cross_val_score(completed_pl, X_train, y_train, scoring=metric, cv=cv, n_jobs=-1)\n",
    "  all_scores.append(scores)\n",
    "\n",
    "for i in range(len(all_scores)):\n",
    "  print(np.mean(all_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw boxplot \n",
    "model_names = ['Ridge', 'SVR', 'DTR', \"KNR\",'GBR']\n",
    "plt.boxplot(all_scores)\n",
    "plt.xticks(np.arange(len(model_names))+1, model_names, rotation=45, fontsize=16)\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "618af10fdd433c84be79e5d9cef7a85d74ad68be7e2e9dd9461a47b527f16862"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
